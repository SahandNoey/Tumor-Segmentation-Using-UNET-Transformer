{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9444961,"sourceType":"datasetVersion","datasetId":5740136},{"sourceId":9445036,"sourceType":"datasetVersion","datasetId":5740193},{"sourceId":9445174,"sourceType":"datasetVersion","datasetId":5740300},{"sourceId":9445408,"sourceType":"datasetVersion","datasetId":5740466}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install patchify","metadata":{"execution":{"iopub.status.busy":"2024-09-20T20:43:54.831056Z","iopub.execute_input":"2024-09-20T20:43:54.831365Z","iopub.status.idle":"2024-09-20T20:44:09.081342Z","shell.execute_reply.started":"2024-09-20T20:43:54.831331Z","shell.execute_reply":"2024-09-20T20:44:09.080319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.insert(1, \"/kaggle/input/unetr2dmetrics\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T20:44:09.083526Z","iopub.execute_input":"2024-09-20T20:44:09.083839Z","iopub.status.idle":"2024-09-20T20:44:09.088909Z","shell.execute_reply.started":"2024-09-20T20:44:09.083806Z","shell.execute_reply":"2024-09-20T20:44:09.087901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nimport numpy as np\nimport cv2\nfrom glob import glob\nfrom sklearn.utils import shuffle\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom sklearn.model_selection import train_test_split\nfrom patchify import patchify\nimport unetr_2d\nfrom unetr_2d import build_unetr_2d\nfrom metrics import dice_loss, dice_coef","metadata":{"execution":{"iopub.status.busy":"2024-09-20T20:44:09.089994Z","iopub.execute_input":"2024-09-20T20:44:09.090241Z","iopub.status.idle":"2024-09-20T20:44:22.339036Z","shell.execute_reply.started":"2024-09-20T20:44:09.090212Z","shell.execute_reply":"2024-09-20T20:44:22.338222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# UNETR  Configration\ncf = {}\ncf[\"image_size\"] = 256\ncf[\"num_channels\"] = 3\ncf[\"num_layers\"] = 12\ncf[\"hidden_dim\"] = 128\ncf[\"mlp_dim\"] = 32\ncf[\"num_heads\"] = 6\ncf[\"dropout_rate\"] = 0.1\ncf[\"patch_size\"] = 16\ncf[\"num_patches\"] = (cf[\"image_size\"]**2)//(cf[\"patch_size\"]**2)\ncf[\"flat_patches_shape\"] = (\n    cf[\"num_patches\"],\n    cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"]\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T20:44:22.340927Z","iopub.execute_input":"2024-09-20T20:44:22.341509Z","iopub.status.idle":"2024-09-20T20:44:22.348009Z","shell.execute_reply.started":"2024-09-20T20:44:22.341470Z","shell.execute_reply":"2024-09-20T20:44:22.347118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def create_dir(path):\n#     if not os.path.exists(path):\n#         os.makedirs(path)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T20:44:22.349086Z","iopub.execute_input":"2024-09-20T20:44:22.349383Z","iopub.status.idle":"2024-09-20T20:44:22.450416Z","shell.execute_reply.started":"2024-09-20T20:44:22.349352Z","shell.execute_reply":"2024-09-20T20:44:22.449476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"def load_dataset(path, split=0.1):\n    \"\"\" Loading the images and masks \"\"\"\n    X = sorted(glob(os.path.join(path, \"images\", \"*.png\")))\n    Y = sorted(glob(os.path.join(path, \"masks\", \"*.png\")))\n\n    \"\"\" Spliting the data into training and testing \"\"\"\n    split_size = int(len(X) * split)\n\n    train_x, valid_x = train_test_split(X, test_size=split_size, random_state=42)\n    train_y, valid_y = train_test_split(Y, test_size=split_size, random_state=42)\n\n    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n\n    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:40:44.351315Z","iopub.execute_input":"2024-09-20T21:40:44.351758Z","iopub.status.idle":"2024-09-20T21:40:44.359432Z","shell.execute_reply.started":"2024-09-20T21:40:44.351718Z","shell.execute_reply":"2024-09-20T21:40:44.358399Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Standardize Images and Masks","metadata":{}},{"cell_type":"code","source":"def read_image(path):\n    path = path.decode()\n    image = cv2.imread(path, cv2.IMREAD_COLOR)\n    image = cv2.resize(image, (cf[\"image_size\"], cf[\"image_size\"]))\n    image = image / 255.0\n\n    \"\"\" Processing to patches \"\"\"\n    patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"])\n    patches = patchify(image, patch_shape, cf[\"patch_size\"])\n    patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n    patches = patches.astype(np.float32)\n\n    return patches\n\ndef read_mask(path):\n    path = path.decode()\n    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (cf[\"image_size\"], cf[\"image_size\"]))\n    mask = mask / 255.0\n    mask = mask.astype(np.float32)\n    mask = np.expand_dims(mask, axis=-1)\n    return mask","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:40:49.363056Z","iopub.execute_input":"2024-09-20T21:40:49.363813Z","iopub.status.idle":"2024-09-20T21:40:49.371563Z","shell.execute_reply.started":"2024-09-20T21:40:49.363770Z","shell.execute_reply":"2024-09-20T21:40:49.370676Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def tf_parse(x, y):\n    def _parse(x, y):\n        x = read_image(x)\n        y = read_mask(y)\n        return x, y\n\n    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n    x.set_shape(cf[\"flat_patches_shape\"])\n    y.set_shape([cf[\"image_size\"], cf[\"image_size\"], 1])\n    return x, y\n\ndef tf_dataset(X, Y, batch=2):\n    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n    ds = ds.map(tf_parse).batch(batch).prefetch(10)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:40:52.448499Z","iopub.execute_input":"2024-09-20T21:40:52.449242Z","iopub.status.idle":"2024-09-20T21:40:52.456107Z","shell.execute_reply.started":"2024-09-20T21:40:52.449202Z","shell.execute_reply":"2024-09-20T21:40:52.455085Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"!touch log.csv","metadata":{"execution":{"iopub.status.busy":"2024-09-20T20:44:29.714671Z","iopub.execute_input":"2024-09-20T20:44:29.715586Z","iopub.status.idle":"2024-09-20T20:44:30.725743Z","shell.execute_reply.started":"2024-09-20T20:44:29.715543Z","shell.execute_reply":"2024-09-20T20:44:30.724730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T20:44:33.548899Z","iopub.execute_input":"2024-09-20T20:44:33.549306Z","iopub.status.idle":"2024-09-20T20:44:33.555129Z","shell.execute_reply.started":"2024-09-20T20:44:33.549270Z","shell.execute_reply":"2024-09-20T20:44:33.554282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n\n    \"\"\" Hyperparameters \"\"\"\n    batch_size = 8\n    lr = 0.1\n    num_epochs = 500\n    model_path = \"/kaggle/working/model.keras\"\n    csv_path = os.path.join(\"/kaggle/working\", \"log.csv\")\n\n    \"\"\" Dataset \"\"\"\n    dataset_path = \"/kaggle/input/braintumordataset\"\n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n\n    print(f\"Train: \\t{len(train_x)} - {len(train_y)}\")\n    print(f\"Valid: \\t{len(valid_x)} - {len(valid_y)}\")\n    print(f\"Test: \\t{len(test_x)} - {len(test_y)}\")\n\n    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n\n    \"\"\" Model \"\"\"\n    model = build_unetr_2d(cf)\n    model.compile(loss=dice_loss, optimizer=SGD(lr), metrics=[dice_coef, \"acc\"])\n    # model.summary()\n\n    callbacks = [\n        ModelCheckpoint(model_path, verbose=1, save_best_only=True, save_freq='epoch'),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n        CSVLogger(csv_path),\n        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n    ]\n\n    model.fit(\n        train_dataset,\n        epochs=num_epochs,\n        validation_data=valid_dataset,\n        callbacks=callbacks\n    )","metadata":{"execution":{"iopub.status.busy":"2024-09-20T20:53:05.478698Z","iopub.execute_input":"2024-09-20T20:53:05.479157Z","iopub.status.idle":"2024-09-20T20:56:28.785739Z","shell.execute_reply.started":"2024-09-20T20:53:05.479116Z","shell.execute_reply":"2024-09-20T20:56:28.784863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def dice_coef(y_true, y_pred, smooth=100):        \n#     y_true_f = K.flatten(y_true)\n#     y_pred_f = K.flatten(y_pred)\n#     intersection = K.sum(y_true_f * y_pred_f)\n#     dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n#     return dice","metadata":{"execution":{"iopub.status.busy":"2024-09-20T20:18:23.906951Z","iopub.execute_input":"2024-09-20T20:18:23.907795Z","iopub.status.idle":"2024-09-20T20:18:23.913620Z","shell.execute_reply.started":"2024-09-20T20:18:23.907754Z","shell.execute_reply":"2024-09-20T20:18:23.912471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.saving import register_keras_serializable\n\n# @register_keras_serializable()\n# def dice_coef(y_true, y_pred, smooth=100):        \n#     y_true_f = K.flatten(y_true)\n#     y_pred_f = K.flatten(y_pred)\n#     intersection = K.sum(y_true_f * y_pred_f)\n#     dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n#     return dice","metadata":{"execution":{"iopub.status.busy":"2024-09-20T20:19:09.101189Z","iopub.execute_input":"2024-09-20T20:19:09.101980Z","iopub.status.idle":"2024-09-20T20:19:09.109736Z","shell.execute_reply.started":"2024-09-20T20:19:09.101936Z","shell.execute_reply":"2024-09-20T20:19:09.108727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.models import load_model\n# import os\n# # Load the model from the .keras file\n# model = load_model(\"/kaggle/input/tmpmodel/model.keras\", custom_objects={'dice_loss': dice_loss})","metadata":{"execution":{"iopub.status.busy":"2024-09-20T20:20:11.214647Z","iopub.execute_input":"2024-09-20T20:20:11.215073Z","iopub.status.idle":"2024-09-20T20:20:16.643239Z","shell.execute_reply.started":"2024-09-20T20:20:11.215036Z","shell.execute_reply":"2024-09-20T20:20:16.642183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir results","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:37:03.739377Z","iopub.execute_input":"2024-09-20T21:37:03.739637Z","iopub.status.idle":"2024-09-20T21:37:04.749747Z","shell.execute_reply.started":"2024-09-20T21:37:03.739607Z","shell.execute_reply":"2024-09-20T21:37:04.748398Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install patchify","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:38:03.096485Z","iopub.execute_input":"2024-09-20T21:38:03.096868Z","iopub.status.idle":"2024-09-20T21:38:17.484312Z","shell.execute_reply.started":"2024-09-20T21:38:03.096834Z","shell.execute_reply":"2024-09-20T21:38:17.483192Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting patchify\n  Downloading patchify-0.2.3-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from patchify) (1.26.4)\nDownloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\nInstalling collected packages: patchify\nSuccessfully installed patchify-0.2.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nsys.path.insert(1, \"/kaggle/input/unetr2dmetrics\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:40:07.370572Z","iopub.execute_input":"2024-09-20T21:40:07.371466Z","iopub.status.idle":"2024-09-20T21:40:07.375495Z","shell.execute_reply.started":"2024-09-20T21:40:07.371424Z","shell.execute_reply":"2024-09-20T21:40:07.374537Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Prediction on Test Data","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nimport numpy as np\nimport cv2\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom patchify import patchify\nfrom metrics import dice_loss, dice_coef\nfrom glob import glob\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom sklearn.model_selection import train_test_split\nfrom patchify import patchify\nimport unetr_2d\nfrom unetr_2d import build_unetr_2d\nfrom metrics import dice_loss, dice_coef\n\n\n\n\"\"\" UNETR  Configration \"\"\"\ncf = {}\ncf[\"image_size\"] = 256\ncf[\"num_channels\"] = 3\ncf[\"num_layers\"] = 12\ncf[\"hidden_dim\"] = 128\ncf[\"mlp_dim\"] = 32\ncf[\"num_heads\"] = 6\ncf[\"dropout_rate\"] = 0.1\ncf[\"patch_size\"] = 16\ncf[\"num_patches\"] = (cf[\"image_size\"]**2)//(cf[\"patch_size\"]**2)\ncf[\"flat_patches_shape\"] = (\n    cf[\"num_patches\"],\n    cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"]\n)\n\n\nif __name__ == \"__main__\":\n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n\n    \"\"\" Load the model \"\"\"\n    model_path = os.path.join(\"/kaggle/input/finalmodel\", \"model.keras\")\n    model = tf.keras.models.load_model(model_path, custom_objects={\"dice_loss\": dice_loss, \"dice_coef\": dice_coef})\n\n    \"\"\" Dataset \"\"\"\n    dataset_path = \"/kaggle/input/braintumordataset\"\n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n\n    print(f\"Train: \\t{len(train_x)} - {len(train_y)}\")\n    print(f\"Valid: \\t{len(valid_x)} - {len(valid_y)}\")\n    print(f\"Test: \\t{len(test_x)} - {len(test_y)}\")\n\n    \"\"\" Prediction \"\"\"\n    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n        \"\"\" Extracting the name \"\"\"\n        name = x.split(\"/\")[-1]\n\n        \"\"\" Reading the image \"\"\"\n        image = cv2.imread(x, cv2.IMREAD_COLOR)\n        image = cv2.resize(image, (cf[\"image_size\"], cf[\"image_size\"]))\n        x = image / 255.0\n\n        patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"])\n        patches = patchify(x, patch_shape, cf[\"patch_size\"])\n        patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n        patches = patches.astype(np.float32)\n        patches = np.expand_dims(patches, axis=0)\n\n        \"\"\" Read Mask \"\"\"\n        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n        mask = cv2.resize(mask, (cf[\"image_size\"], cf[\"image_size\"]))\n        mask = mask / 255.0\n        mask = np.expand_dims(mask, axis=-1)\n        mask = np.concatenate([mask, mask, mask], axis=-1)\n\n        \"\"\" Prediction \"\"\"\n        pred = model.predict(patches, verbose=0)[0]\n        pred = np.concatenate([pred, pred, pred], axis=-1)\n\n        \"\"\" Save final mask \"\"\"\n        line = np.ones((cf[\"image_size\"], 10, 3)) * 255\n        cat_images = np.concatenate([image, line, mask*255, line, pred*255], axis=1)\n        save_image_path = os.path.join(\"/kaggle/working/results\",  name)\n        cv2.imwrite(save_image_path, cat_images)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:42:54.222219Z","iopub.execute_input":"2024-09-20T21:42:54.222920Z","iopub.status.idle":"2024-09-20T21:43:31.214950Z","shell.execute_reply.started":"2024-09-20T21:42:54.222880Z","shell.execute_reply":"2024-09-20T21:43:31.213984Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Train: \t2452 - 2452\nValid: \t306 - 306\nTest: \t306 - 306\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/306 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1726868582.031593     160 service.cc:145] XLA service 0x7b2a08003f20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1726868582.031646     160 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1726868585.339245     160 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n100%|██████████| 306/306 [00:31<00:00,  9.74it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r results.zip /kaggle/working/results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle datasets download ","metadata":{},"execution_count":null,"outputs":[]}]}